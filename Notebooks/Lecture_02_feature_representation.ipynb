{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can follow along and play with this notebook by clicking the badge below\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jasongfleischer/UCSD_COGS118A/blob/main/Notebooks/Lecture_02_feature_representation.ipynb)\n",
    "\n",
    "\n",
    "# Feature representation\n",
    "\n",
    "1. Standardizing (z-transform), log transform, and other normalizations\n",
    "2. One hot encoding\n",
    "3. Representing image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "#also in preprocessing: QunatileTransformer, MinMaxScaler and others!\n",
    "\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "\n",
    "import requests # need to use HTTP stream to load data from Github inside Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset('penguins').dropna() # dropna() gets rid of rows with missing data\n",
    "penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. StandardScaler() et al.\n",
    "Let's re-scale the real valued inputs.  If we have variables that are a couple of orders of magnitude higher numbers than others, some machine learning algorithms will key on the big values and ignore the small values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = penguins.drop(['species','island','sex'], axis=1)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.hist(); \n",
    "plt.tight_layout(); #necessary to keep the subfigure titles from overlapping other rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data is now z-transformed... this is \"standard deviations from the mean of the column\" now\n",
    "X_s = pd.DataFrame( StandardScaler().fit_transform(X), columns=X.columns, index=X.index)\n",
    "\n",
    "X_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_s.hist(); \n",
    "plt.tight_layout(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l = X.apply(lambda x: np.log(x)) #log transform the data to make it look more normal\n",
    "\n",
    "X_l.hist() \n",
    "plt.tight_layout(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log transform and then scale...  its still not really normal but it is less skew on some body & bill measures\n",
    "X_ls = pd.DataFrame( StandardScaler().fit_transform(X_l), columns=X_l.columns, index=X_l.index)\n",
    "\n",
    "X_ls.hist() \n",
    "plt.tight_layout(); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. OneHotEncoder()\n",
    "\n",
    "Ok there are 3 categorical variables in the data... species, island it was found on, and sex of the bird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.species.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.island.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.sex.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder =  OneHotEncoder().fit( penguins[['species','island', 'sex']] )\n",
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = encoder.transform( penguins[['species','island', 'sex']] ).toarray() \n",
    "# toarray() turns the output from a sparse to a dense matrix\n",
    "\n",
    "transformed\n",
    "# 1st 3 columns are species, next 3 columns are island, last 2 columns are sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, category in enumerate( np.concatenate(encoder.categories_) ):\n",
    "    X_s[category] = transformed[:,index]\n",
    "    \n",
    "X_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_s.hist(); \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all the categorical variables are OneHot, all the real variables have been scaled, and **ALL** variables are on the same order of magnitude so there's no variable-favoritism that can happen :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Image encoding\n",
    "\n",
    "Images can be encoded numerically.  Typically this will be in a color space which you can think of as a vector space.  For grayscale (like below) this is done by putting the pixels into an array... rows and column represent the rows and columns of the images.  The number at each matrix location is a number between 0 and 255 (8 bits) which denotes the brightness of the image... bigger numbers are close to white, smaller numbers are close to black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im0 = np.array( [[0,0,0,0,0,200,200,200,200,200],\n",
    "       [0,0,0,0,0,200,200,200,200,200],\n",
    "       [0,0,0,0,0,200,200,200,200,200],\n",
    "       [0,0,0,0,0,200,200,200,200,200],\n",
    "       [0,0,0,0,0,200,200,200,200,200],\n",
    "       [0,0,0,0,0,200,200,200,200,200],\n",
    "       [0,0,0,0,0,200,200,200,200,200],\n",
    "       [0,0,0,0,0,200,200,200,200,200],\n",
    "       [0,0,0,0,0,200,200,200,200,200],\n",
    "       [0,0,0,0,0,200,200,200,200,200]\n",
    "      ])\n",
    "im0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im0,cmap='gray',vmin=0,vmax=255);\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use a color image, we will likely be in RGB color space (but other color spaces are possible!).  Each pixel is now a 3-D vector $(x_1,x_2,x_3)$ with the numbers representing Red, Green, and Blue intensity respectively "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b = [0,0,0] # black is all zeros\n",
    "y = [255,255,0] # yellow is red + green in additive color mixing \n",
    "\n",
    "im1 =  np.array(\n",
    "       [[b,b,b,b,y,y,b,b,b,b],\n",
    "        [b,b,y,y,y,y,y,y,b,b],\n",
    "        [b,y,y,y,y,y,y,y,y,b],\n",
    "        [b,y,y,b,y,y,b,y,y,b],\n",
    "        [y,y,y,y,y,y,y,y,y,y],\n",
    "        [y,y,b,y,y,y,y,b,y,y],\n",
    "        [b,y,y,b,b,b,b,y,y,b],\n",
    "        [b,y,y,y,y,y,y,y,y,b],\n",
    "        [b,b,y,y,y,y,y,y,b,b],\n",
    "        [b,b,b,b,y,y,b,b,b,b]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im1);\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so that's what image data looks like.  \n",
    "\n",
    "But images are 3-D data: pixel rows x pixel columns x color vectors. We talk about machine learning algorithms taking an input that's a 1-D vector.  And the penguin example above is like that... each penguin is represented as a 1-D vector of numbers\n",
    "\n",
    "How can we take a 3-D matrix and make it 1-D?  NumPy provides a method .flatten() which unravels  first the 3rd dimension (color), then the 2nd dimension (columns), and then lastly the 1st dimension (rows).\n",
    "\n",
    "So we start with \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "[R_{(0,0)},G_{(0,0)},B_{(0,0)}] & \\cdots & [R_{(0,m)},G_{(0,m)},B_{(0,m)}] \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "[R_{(n,0)},G_{(n,0)},B_{(n,0)}] & \\cdots & [R_{(n,m)},G_{(n,m)},B_{(n,m)}]\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "And get out \n",
    "\n",
    "$$ [R_{(0,0)},G_{(0,0)},B_{(0,0)}, R_{(0, 1)}, \\cdots, B_{(0,m)}, R_{(1,0)}, \\cdots \\cdots B_{(n,m)} ] $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1.flatten() # unraveled in the order above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's another image, one that's a bit more complicated than our smiley\n",
    "im2 = Image.open(\n",
    "    requests.get('https://github.com/jasongfleischer/UCSD_COGS118A/raw/main/Notebooks/data/party-popper_1f389.png', stream=True).raw\n",
    ")\n",
    "\n",
    "im2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK, we want to make a dataset, so we need to downsize the giant popper to match im1, and set it up in the same format\n",
    "\n",
    "im2a = np.array( im2.resize((10,10)).convert('RGB').getdata() ).flatten()\n",
    "im2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdata = pd.DataFrame( [im1.flatten(),im2a], index=['smiley','popper'] )\n",
    "# cool, here's some data to train our algorithm on!\n",
    "\n",
    "imdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
